<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLM on Chuck</title><link>https://xuchengpeng.github.io/hugo-x/tags/llm/</link><description>Recent content in LLM on Chuck</description><generator>Hugo</generator><language>en</language><managingEditor>chuckxcp@qq.com (Chuck)</managingEditor><webMaster>chuckxcp@qq.com (Chuck)</webMaster><lastBuildDate>Mon, 10 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://xuchengpeng.github.io/hugo-x/tags/llm/index.xml" rel="self" type="application/rss+xml"/><item><title>llama.cpp使用</title><link>https://xuchengpeng.github.io/hugo-x/posts/llama-cpp-usage/</link><pubDate>Mon, 10 Feb 2025 00:00:00 +0000</pubDate><author>chuckxcp@qq.com (Chuck)</author><guid>https://xuchengpeng.github.io/hugo-x/posts/llama-cpp-usage/</guid><description>&lt;p&gt;前面的一篇文章介绍了&lt;a href="../ollama-run-deepseek-r1/"&gt;Ollama运行DeepSeek-R1&lt;/a&gt;，实际上Ollama的后端使用的是&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;。&lt;/p&gt;</description></item><item><title>Ollama运行DeepSeek-R1</title><link>https://xuchengpeng.github.io/hugo-x/posts/ollama-run-deepseek-r1/</link><pubDate>Sat, 08 Feb 2025 00:00:00 +0000</pubDate><author>chuckxcp@qq.com (Chuck)</author><guid>https://xuchengpeng.github.io/hugo-x/posts/ollama-run-deepseek-r1/</guid><description>&lt;p&gt;&lt;a href="https://ollama.com/"&gt;Ollama&lt;/a&gt; 是一个用于构建大型语言模型应用的工具，它提供了一个简洁易用的命令行界面和服务器，让你能够轻松下载、运行和管理各种开源LLM。&lt;/p&gt;</description></item><item><title>Emacs中使用大型语言模型</title><link>https://xuchengpeng.github.io/hugo-x/posts/using-llm-in-emacs/</link><pubDate>Sat, 11 Jan 2025 00:00:00 +0000</pubDate><author>chuckxcp@qq.com (Chuck)</author><guid>https://xuchengpeng.github.io/hugo-x/posts/using-llm-in-emacs/</guid><description>&lt;p&gt;Emacs有不少LLM的客户端，这里我们选择&lt;a href="https://github.com/karthink/gptel"&gt;gptel&lt;/a&gt;，在 &lt;code&gt;init.el&lt;/code&gt; 中添加以下代码：&lt;/p&gt;</description></item></channel></rss>